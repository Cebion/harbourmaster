#!/usr/bin/env python3

import contextlib
import datetime
import fnmatch
import hashlib
import json
import os
import pathlib
import platform
import re
import shutil
import sys
import tempfile
import textwrap
import zipfile

from difflib import Differ
from pathlib import Path
from urllib.parse import urlparse, urlunparse

################################################################################
## This speeds up harbourmaster from 4-5 seconds to 1-2 seconds.
##
## Insert our extra modules.
PYLIB_ZIP     = Path(__file__).parent / 'pylibs.zip'
PYLIB_ZIP_MD5 = Path(__file__).parent / 'pylibs.zip.md5'
PYLIB_PATH    = Path(__file__).parent / 'pylibs'

if platform.system() in ('Darwin', 'Windows'):
    EXLIB_PATH = Path(__file__).parent / 'exlibs'
    sys.path.insert(0, str(EXLIB_PATH))
    sys.path.insert(0, str(PYLIB_PATH))

else:
    if PYLIB_ZIP.is_file():
        if PYLIB_PATH.is_dir():
            shutil.rmtree(PYLIB_PATH)

        PYLIB_PATH.mkdir(0o755)
        with zipfile.ZipFile(PYLIB_ZIP, 'r') as zf:
            zf.extractall(PYLIB_PATH)

        md5_check = hashlib.md5()
        with PYLIB_ZIP.open('rb') as fh:
            while True:
                data = fh.read(1024 * 1024)
                if len(data) == 0:
                    break

                md5_check.update(data)

        with PYLIB_ZIP_MD5.open('wt') as fh:
            fh.write(md5_check.hexdigest())

        del md5_check

        PYLIB_ZIP.unlink()

    sys.path.insert(0, str(PYLIB_PATH))

################################################################################
## Now load the stuff we include
import loguru
import requests
import utility

from utility import cprint, cstrip

logger = loguru.logger.opt(colors=True)

################################################################################
## Override this for custom tools/ports directories
TOOLS_DIR=None
PORTS_DIR=None
UPDATE_FREQUENCY=(60 * 60 * 3) # Only check automatically every few hours.

SOURCE_DEFAULTS = {
    "020_portmaster.source.json": textwrap.dedent("""
    {
        "prefix": "pm",
        "api": "PortMasterV1",
        "name": "PortMaster",
        "url": "https://api.github.com/repos/PortsMaster/PortMaster-Releases/releases/latest",
        "last_checked": null,
        "version": 1,
        "data": {}
    }
    """),
    "021_runtimes.source.json": textwrap.dedent("""
    {
        "prefix": "pr",
        "api": "GitHubRawReleaseV1",
        "name": "PortMaster Runtime",
        "url": "https://api.github.com/repos/PortsMaster/PortMaster-Runtime/releases/latest",
        "last_checked": null,
        "version": 1,
        "data": {}
    }
    """),
    }

TESTING=False
################################################################################
## The following code is a simplification of the PortMaster toolsloc and whichsd code.
DEFAULT_PORTS_DIR = Path("/roms/ports")

if platform.system() in ('Darwin', 'Windows'):
    ## For testing
    DEFAULT_TOOLS_DIR = Path('.').absolute()
    DEFAULT_PORTS_DIR = Path('ports/').absolute()
    TESTING=True
elif Path("/opt/tools/PortMaster/").is_dir():
    DEFAULT_TOOLS_DIR = Path("/opt/tools")
elif Path("/opt/system/Tools/PortMaster/").is_dir():
    DEFAULT_TOOLS_DIR = Path("/opt/system/Tools")
elif Path("/storage/roms/ports").is_dir():
    DEFAULT_TOOLS_DIR = Path("/storage/roms/ports")
    DEFAULT_PORTS_DIR = Path("/storage/roms/ports")
else:
    DEFAULT_TOOLS_DIR = Path("/roms/ports")

if Path("/roms2/ports").is_dir():
    DEFAULT_PORTS_DIR = Path("/roms2/ports")

## Default TOOLS_DIR
if TOOLS_DIR is None:
    if 'TOOLS_DIR' in os.environ:
        TOOLS_DIR = Path(os.environ['TOOLS_DIR'])
    else:
        TOOLS_DIR = DEFAULT_TOOLS_DIR
elif isinstance(TOOLS_DIR, str):
    TOOLS_DIR = Path(TOOLS_DIR).resolve()
elif isinstance(TOOLS_DIR, pathlib.PurePath):
    # This is good.
    pass
else:
    logger.error(f"{TOOLS_DIR!r} is set to something weird.")
    exit(255)

## Default PORTS_DIR
if PORTS_DIR is None:
    if 'PORTS_DIR' in os.environ:
        PORTS_DIR = Path(os.environ['PORTS_DIR']).resolve()
    else:
        PORTS_DIR = DEFAULT_PORTS_DIR
elif isinstance(ports_dir, str):
    PORTS_DIR = Path(PORTS_DIR).resolve()
elif isinstance(PORTS_DIR, pathlib.PurePath):
    # This is good.
    pass
else:
    logger.error(f"{PORTS_DIR!r} is set to something weird.")
    exit(255)

LOG_FILE = TOOLS_DIR / "PortMaster" / "harbourmaster.txt"
if LOG_FILE.parent.is_dir():
    LOG_FILE_HANDLE = logger.add(LOG_FILE, backtrace=True, diagnose=True)

# print(f"PORTS_DIR: {PORTS_DIR}")
# print(f"TOOLS_DIR: {TOOLS_DIR}")

################################################################################
## Utils
def fetch(url):
    r = requests.get(url)
    if r.status_code != 200:
        logger.error(f"Failed to download <b>{url!r}</b>: <b>{r.status_code}</b>")
        return None

    return r


def fetch_data(url):
    r = fetch(url)
    if r is None:
        return None

    return r.content


def fetch_json(url):
    r = fetch(url)
    if r is None:
        return None

    return r.json()


def fetch_text(url):
    r = fetch(url)
    if r is None:
        return None

    return r.text


def nice_size(size):
    suffixes = ('B', 'KB', 'MB', 'GB')
    for suffix in suffixes:
        if size < 768:
            break

        size /= 1024

    if suffix == 'B':
        return f"{size:.0f} {suffix}"

    return f"{size:.02f} {suffix}"


def download(file_name, file_url, md5_source=None, md5_result=None):
    """
    Download a file from file_url into file_name, checks the md5sum of the file against md5_source if given.

    returns file_name if successful, otherwise None.
    """
    if md5_result is None:
        md5_result = [None]

    r = requests.get(file_url, stream=True)

    if r.status_code != 200:
        logger.error(f"Unable to download file: {file_url!r} [{r.status_code}]")
        return None

    total_length = r.headers.get('content-length')
    if total_length is None:
        total_length = None
        total_length_mb = "???? MB"
    else:
        total_length = int(total_length)
        total_length_mb = nice_size(total_length)

    md5 = hashlib.md5()

    cprint(f"Downloading <b>{file_url!r}</b> - <b>{total_length_mb}</b>")

    length = 0
    with file_name.open('wb') as fh:
        for data in r.iter_content(chunk_size=104096, decode_unicode=False):
            md5.update(data)
            fh.write(data)
            length += len(data)

            if total_length is None:
                sys.stdout.write(f"\r[{'?' * 40}] - {nice_size(length)} / {total_length_mb} ")
            else:
                amount = int(length / total_length * 40)
                sys.stdout.write(f"\r[{'|' * amount}{' ' * (40 - amount)}] - {nice_size(length)} / {total_length_mb} ")
            sys.stdout.flush()

        cprint("\n")

    md5_file = md5.hexdigest()
    if md5_source is not None:
        if md5_file != md5_source:
            zip_file.unlink()
            logger.error(f"File doesn't match the md5 file: {md5_file} != {md5_source}")
            return None
        else:
            cprint(f"<b,g,>Passed md5 check.</b,g,>")
    else:
        logger.warning(f"No md5 to check against: <b>{md5_file}</b>")

    md5_result[0] = md5_file

    return file_name


def datetime_compare(time_a, time_b=None):
    if isinstance(time_a, str):
        time_a = datetime.datetime.fromisoformat(time_a)

    if time_b is None:
        time_b = datetime.datetime.now()
    elif isinstance(time_b, str):
        time_b = datetime.datetime.fromisoformat(time_b)

    return (time_b - time_a).seconds


def add_unique(base_list, value):
    if value not in base_list:
        base_list.append(value)


def add_unique_list(base_dict, key, value):
    if key not in base_dict:
        base_dict[key] = value
        return

    if isinstance(base_dict[key], str):
        if base_dict[key] == value:
            return

        base_dict[key] = [base_dict[key]]

    if value not in base_dict[key]:
        base_dict[key].append(value)


def get_list(base_dict, key):
    if key not in base_dict:
        return []

    result = base_dict[key]
    if isinstance(result, str):
        return [result]

    if result is None:
        ## CEBION STRIKES AGAIN
        return []

    return result


@contextlib.contextmanager
def make_temp_directory():
    temp_dir = tempfile.mkdtemp()
    try:
        yield Path(temp_dir)

    finally:
        shutil.rmtree(temp_dir)


################################################################################
## Raw Downloader

def raw_download(save_path, file_url):
    """
    This is a bit of a hack, this acts as a source of ports, but for raw urls.
    This only supports downloading so not bothering to add it as a full blown source.
    """
    original_url = file_url
    url_info = urlparse(file_url)
    file_name = url_info.path.rsplit('/', 1)[1]

    if file_name.endswith('.md5') or file_name.endswith('.md5sum'):
        ## If it is an md5 file, we assume the actual zip is sans the md5/md5sum
        md5_source = fetch_text(file_url)
        if md5_source is None:
            logger.error(f"Unable to download file: {file_url!r} [{r.status_code}]")

        md5_source = md5_source.strip().split(' ', 1)[0]

        file_name = file_name.rsplit('.', 1)[0]
        file_url = urlunparse(url_info._replace(path=url_info.path.rsplit('.', 1)[0]))
    else:
        md5_source = None

    if not file_name.endswith('.zip'):
        logger.error(f"Unable to download file: {file_url!r} [doesn't end with '.zip']")
        return None

    file_name = file_name.replace('%20', '.').replace('+', '.').replace('..', '.')

    md5_result = [None]
    zip_file = download(save_path / file_name, file_url, md5_source, md5_result)

    zip_info = PortInfo({})

    zip_info.md5 = md5_result[0]
    zip_info.source = f"url/{zip_file.name}"
    zip_info.zip_file = zip_file
    zip_info.attr['url'] = original_url

    # print(f"-- {zip_info} --")

    cprint("<b,g,>Success!</b,g,>")
    return zip_info


################################################################################
## APIS
class BaseSource():
    VERSION = 0

    def __init__(self, hm, file_name, config):
        pass


class GitHubRawReleaseV1(BaseSource):
    VERSION = 2

    def __init__(self, hm, file_name, config):
        self._hm = hm
        self._file_name = file_name
        self._config = config
        self._prefix = config['prefix']
        self._did_update = False


        if hm.config['no-check']:
            self.load()
        elif config['version'] != self.VERSION:
            cprint(f"<b>{self._config['name']}</b>: Cache out of date.")
            self.update()
        elif self._config['last_checked'] is None:
            cprint(f"<b>{self._config['name']}</b>: First check.")
            self.update()
        elif datetime_compare(self._config['last_checked']) > UPDATE_FREQUENCY:
            cprint(f"<b>{self._config['name']}</b>: Auto Update.")
            self.update()
        else:
            self.load()

    def load(self):
        self._data = self._config.setdefault('data', {}).setdefault('data', {})
        self.ports = self._config.setdefault('data', {}).setdefault('ports', [])
        self.utils = self._config.setdefault('data', {}).setdefault('utils', [])
        self._load()

    def save(self):
        with self._file_name.open('w') as fh:
            json.dump(self._config, fh, indent=4)

    def clean_name(self, text):
        return text.casefold()

    def _load(self):
        """
        Overload to add additional loading.
        """
        ...

    def _update(self):
        """
        Overload to add additional loading.
        """
        ...

    def _clear(self):
        """
        Overload to add additional loading.
        """
        ...

    def update(self):
        cprint(f"<b>{self._config['name']}</b>: updating")
        self._clear()
        self._data = {}
        self.ports = []
        self.utils = []

        if self._did_update:
            cprint(f"- <b>{self._config['name']}</b>: up to date already.")
            return

        cprint(f"- <b>{self._config['name']}</b>: Fetching latest ports")
        data = fetch_json(self._config['url'])
        if data is None:
            return

        ## Load data from the assets.
        for asset in data['assets']:
            result = {
                'name': asset['name'],
                'size': asset['size'],
                'url': asset['browser_download_url'],
                }

            self._data[self.clean_name(asset['name'])] = result

            if asset['name'].lower().endswith('.squashfs'):
                self.utils.append(self.clean_name(asset['name']))

        self._update()

        self._config['version'] = self.VERSION

        self._config['data']['ports'] = self.ports
        self._config['data']['utils'] = self.utils
        self._config['data']['data']  = self._data

        self._config['last_checked'] = datetime.datetime.now().isoformat()

        self.save()
        self._did_update = True
        cprint(f"- <b>{self._config['name']}:</b> Done.")

    def download(self, port_name, temp_dir=None, md5_result=None):
        if md5_result is None:
            md5_result = [None]

        if port_name not in self._data:
            logger.error(f"Unable to find port <b>{port_name}</b>")
            return None

        if temp_dir is None:
            temp_dir = self._hm.temp_dir

        if (port_name + '.md5') in self._data:
            md5_file = port_name + '.md5'
        elif (port_name + '.md5sum') in self._data:
            md5_file = port_name + '.md5sum'
        else:
            logger.error(f"Unable to find md5 for <b>{port_name}</b>")
            return None

        md5_source = fetch_text(self._data[md5_file]['url'])
        if md5_source is None:
            logger.error(f"Unable to download md5 file: {self._data[port_name + '.md5']['url']!r}")
            return None

        md5_source = md5_source.strip().split(' ', 1)[0]

        zip_file = download(temp_dir / port_name, self._data[port_name]['url'], md5_source)

        if zip_file is not None:
            cprint("<b,g,>Success!</b,g,>")

        md5_result[0] = md5_source

        return zip_file

    def port_info(self, port_name):
        port_name = self.clean_name(port_name)

        if port_name not in getattr(self, '_info', {}):
            return {}

        return self._info[port_name]

    def portmd(self, port_name):
        port_info = self.port_info(port_name)
        output = []

        if 'opengl' in port_info["attr"]["reqs"]:
            output.append(f'<r>Title_F</r>="<y>{port_info["attr"]["title"].replace(" ", "_")} .</y>"')
        elif 'power' in port_info["attr"]['reqs']:
            output.append(f'<r>Title_P</r>="<y>{port_info["attr"]["title"].replace(" ", "_")} .</y>"')
        else:
            output.append(f'<r>Title</r>="<y>{port_info["attr"]["title"].replace(" ", "_")} .</y>"')

        output.append(f'<r>Desc</r>="<y>{port_info["attr"]["desc"]}</y>"')
        output.append(f'<r>porter</r>="<y>{port_info["attr"]["porter"]}</y>"')
        output.append(f'<r>locat</r>="<y>{self._prefix}/{port_info["source"]}</y>"')
        if port_info["attr"]['rtr']:
            output.append(f'<r>runtype</r>="<e>rtr</e>"')
        if port_info["attr"]['runtime'] == "mono-6.12.0.122-aarch64.squashfs":
            output.append(f'<r>mono</r>="<e>y</e>"')

        output.append(f'<r>genres</r>="<m>{",".join(port_info["attr"]["genres"])}</m>"')

        return ' '.join(output)


class PortMasterV1(GitHubRawReleaseV1):
    VERSION = 2

    def _load(self):
        self._info = self._config.setdefault('data', {}).setdefault('info', {})

    def _clear(self):
        self._info = {}

    def _update(self):

        cprint(f"- <b>{self._config['name']}</b>: Fetching info")
        # portsmd_url = "https://raw.githubusercontent.com/kloptops/PortMaster/main/ports.md"
        portsmd_url = self._data['ports.md']['url']
        for line in fetch_text(portsmd_url).split('\n'):
            line = line.strip()
            if line == '':
                continue

            port_info = self._portsmd_to_portinfo(line)

            self._info[port_info['source']] = port_info

            self.ports.append(port_info['source'])

        self._config['data']['info']  = self._info

    def _portsmd_to_portinfo(self, text):
        # Super jank
        raw_info = {
            'title': '',
            'desc': '',
            'locat': '',
            'porter': '',
            'reqs': [],
            'rtr': False,
            'runtime': None,
            'genres': [],
            }

        for key, value in re.findall(r'(?:^|\s)(\w+)=\"(.+?)"(?=\s+\w+=|$)', text.strip()):
            key = key.casefold()
            if key == 'title_f':
                raw_info['reqs'].append('opengl')
                key = 'title'
            elif key == 'title_p':
                raw_info['reqs'].append('power')
                key = 'title'

            if key == 'title':
                value = value[:-2].replace('_', ' ')

            # Zips with spaces in their names get replaced with '.'
            if '%20' in value:
                value = value.replace('%20', '.')
                value = value.replace('..', '.')

            # Special keys
            if key == 'runtype':
                key, value = "rtr", True
            elif key == "mono":
                key, value = "runtime", "mono-6.12.0.122-aarch64.squashfs"
            elif key == "genres":
                value = value.split(',')

            raw_info[key] = value

        port_info = PortInfo({})

        port_info.source = self.clean_name(raw_info['locat'])
        ## SUPER JANK --
        from ports_info import ports_info

        port_info.items = ports_info['ports'].get(port_info.source, {'items': []})['items']
        port_info.attr['title']   = raw_info['title']
        port_info.attr['porter']  = raw_info['porter']
        port_info.attr['desc']    = raw_info['desc']
        port_info.attr['rtr']     = raw_info['rtr']
        port_info.attr['reqs']    = raw_info['reqs']
        port_info.attr['runtime'] = raw_info['runtime']
        port_info.attr['genres']  = raw_info['genres']

        return port_info.to_dict()

    def download(self, port_name, temp_dir=None):
        md5_result = [None]
        zip_file = super().download(port_name, temp_dir, md5_result)

        if port_name in self.utils:
            ## Utils
            return zip_file

        zip_info = PortInfo({})

        zip_info.md5 = md5_result[0]
        zip_info.source = f"{self._prefix}/{port_name}"
        zip_info.zip_file = zip_file

        port_info = self.port_info(port_name)
        zip_info.merge_info(port_info)

        # print(f"Port Info {port_info}")
        # print(f"Zip Info {zip_info.to_dict()}")

        return zip_info


class GitHubRepoV1(GitHubRawReleaseV1):
    VERSION = 2

    def _load(self):
        """
        Overload to add additional loading.
        """
        self._info = self._config.setdefault('data', {}).setdefault('info', {})

    def update(self):
        cprint(f"<b>{self._config['name']}</b>: updating")
        if self._did_update:
            cprint(f"- <b>{self._config['name']}</b>: up to date already.")
            return

        self._clear()
        self._data = {}
        self._info = {}
        self.ports = []
        self.utils = []

        user_name = self._config['config']['user_name']
        repo_name = self._config['config']['repo_name']
        branch_name = self._config['config']['branch_name']
        sub_folder = self._config['config']['sub_folder']

        git_url = f"https://api.github.com/repos/{user_name}/{repo_name}/git/trees/{branch_name}?recursive=true"

        cprint(f"- <b>{self._config['name']}</b>: Fetching latest ports")
        git_info = fetch_json(git_url)
        if git_info is None:
            return None

        ports_json_file = None

        for item in git_info['tree']:
            path = item["path"]
            if not path.startswith(sub_folder):
                continue

            name = path.rsplit('/', 1)[1]

            if not (path.endswith('.zip') or
                    path.endswith('.md5') or
                    path.endswith('.squashfs') or
                    path.endswith('.md5sum') or
                    name == 'ports.json'):
                continue

            result = {
                'name': name,
                'size': item['size'],
                'url': f"https://github.com/{user_name}/{repo_name}/raw/{branch_name}/{path}",
                }

            name = self.clean_name(name)
            self._data[name] = result

            if name.endswith('.squashfs'):
                self.utils.append(self.clean_name(asset['name']))

            if name == 'ports.json':
                ports_json_file = name

        if ports_json_file is not None:
            cprint(f"- <b>{self._config['name']}:</b> Fetching info.")
            ports_json = fetch_json(self._data[ports_json_file]['url'])

            for port_info in ports_json['ports']:
                port_name = port_info['source']
                if '/' in port_name:
                    port_name = port_name.rsplit('/', 1)[1]

                port_name = self.clean_name(port_name)

                self._info[port_name] = port_info

                self.ports.append(port_name)

        self._config['version'] = self.VERSION

        self._config['data']['ports'] = self.ports
        self._config['data']['utils'] = self.utils
        self._config['data']['data']  = self._data
        self._config['data']['info']  = self._info

        self._config['last_checked'] = datetime.datetime.now().isoformat()

        self.save()
        self._did_update = True
        cprint(f"- <b>{self._config['name']}:</b> Done.")

    def download(self, port_name, temp_dir=None):
        md5_result = [None]
        zip_file = super().download(port_name, temp_dir, md5_result)

        if port_name in self.utils:
            ## Utils
            return zip_file

        zip_info = PortInfo({})

        zip_info.md5 = md5_result[0]
        zip_info.source = f"{self._prefix}/{port_name}"
        zip_info.zip_file = zip_file

        zip_info.merge_info(self.port_info(port_name))

        return zip_info


SOURCE_APIS = {
    'GitHubRawReleaseV1': GitHubRawReleaseV1,
    'PortMasterV1': PortMasterV1,
    'GitHubRepoV1': GitHubRepoV1,
    }

################################################################################
## Port Information
class PortInfo():
    VERSION = 1
    __attrs__ = (
        'version', 'source', 'items', 'items', 'items_opt', 'md5', 'attr')

    def __init__(self, info):
        if isinstance(info, pathlib.PurePath):
            with info.open('r') as fh:
                self.from_dict(json.load(fh))

        elif isinstance(info, dict):
            self.from_dict(info)

        else:
            raise ValueError(str(info))

    def from_dict(self, info):
        self.version = info.get('source', self.VERSION)
        self.source  = info.get('source', None)
        self.items   = info.get('items', None)
        self.items_opt = info.get('items_opt', None)
        self.md5  = info.get('md5', None)
        self.attr = info.get('attr', {})
        self.attr.setdefault('title', "")
        self.attr.setdefault('desc', "")
        self.attr.setdefault('inst', "")
        self.attr.setdefault('genres', [])
        self.attr.setdefault('porter', "")
        self.attr.setdefault('image', None)
        self.attr.setdefault('rtr', False)
        self.attr.setdefault('runtime', None)
        self.attr.setdefault('reqs', [])

    def merge_info(self, other):
        BLANK = object()

        if isinstance(other, (str, dict)):
            other = PortInfo(other)

        elif isinstance(other, PortInfo):
            pass

        else:
            raise ValueError(str(info))

        for attr in self.__attrs__:
            value_a = getattr(self, attr)
            value_b = getattr(other, attr, BLANK)

            if value_b is BLANK:
                continue

            if value_a is None or value_a == "" or value_a == []:
                setattr(self, attr, value_b)

            if value_b in (True, False) and value_a in (True, False, None):
                setattr(self, attr, value_b)
                continue

            if isinstance(value_b, str) and value_a in ("", None):
                setattr(self, attr, value_b)
                continue

            if isinstance(value_b, list) and value_a in ([], None):
                setattr(self, attr, value_b)
                continue

            if attr == 'attr':
                for key in value_b.keys():
                    if key not in value_a:
                        value_a[key] = value_b[key]
                        continue

                    if value_b[key] in (True, False) and value_a[key] in (True, False, None):
                        value_a[key] = value_b[key]
                        continue

                    if isinstance(value_b[key], str) and value_a[key] in ("", None):
                        value_a[key] = value_b[key]
                        continue

                    if isinstance(value_b[key], list) and value_a[key] in ([], None):
                        value_a[key] = value_b[key]
                        continue

    @property
    def dirs(self):
        return [
            item[:-1]
            for item in self.items
            if item.endswith('/')]

    @property
    def scripts(self):
        return [
            item
            for item in self.items
            if not item.endswith('/')]

    def to_dict(self):
        return {
            attr: getattr(self, attr)
            for attr in self.__attrs__
            }

    def __str__(self):
        return str(self.to_dict())

    def __repr__(self):
        return str(self.to_dict())


################################################################################
## Config loading
class HarbourMaster():
    CONFIG_VERSION = 1
    DEFAULT_CONFIG = {
        'version': CONFIG_VERSION,
        'first_run': True,
        }

    def __init__(self, config, *, tools_dir=None, ports_dir=None, temp_dir=None):
        """
        config = load_config()
        """

        if tools_dir is None:
            tools_dir = TOOLS_DIR

        if ports_dir is None:
            ports_dir = PORTS_DIR

        if isinstance(tools_dir, str):
            tools_dir = Path(tools_dir)
        elif not isinstance(tools_dir, pathlib.PurePath):
            raise ValueError('tools_dir')

        if isinstance(ports_dir, str):
            ports_dir = Path(ports_dir)
        elif not isinstance(ports_dir, pathlib.PurePath):
            raise ValueError('ports_dir')


        self.temp_dir  = temp_dir
        self.tools_dir = tools_dir
        self.cfg_dir   = tools_dir / "PortMaster" / "config"
        self.libs_dir  = tools_dir / "PortMaster" / "libs"
        self.ports_dir = ports_dir
        self.sources = {}
        self.config = {
            'no-check': config.get('no-check', False),
            'quiet': config.get('quiet', False),
            'debug': config.get('debug', False),
            }

        self.ports = []
        self.utils = []

        if not self.cfg_dir.is_dir():
            self.cfg_dir.mkdir(0o755, parents=True)

            for source_name in SOURCE_DEFAULTS:
                with (self.cfg_dir / source_name).open('w') as fh:
                    fh.write(SOURCE_DEFAULTS[source_name])

        self.load_sources()

        self.load_ports()


    def load_sources(self):
        source_files = list(self.cfg_dir.glob('*.source.json'))
        source_files.sort()

        check_keys = {'version': None, 'prefix': None, 'api': SOURCE_APIS, 'name': None, 'last_checked': None, 'data': None}
        for source_file in source_files:
            with source_file.open() as fh:
                source_data = json.load(fh)

                fail = False
                for check_key, check_value in check_keys.items():
                    if check_key not in source_data:
                        logger.error(f"Missing key {check_key!r} in <b>{source_file}</b>.")
                        fail = True
                        break

                    if check_value is not None and source_data[check_key] not in check_value:
                        logger.error(f"Unknown {check_key!r} in <b>{source_file}</b>: {source_data[check_key]}.")
                        fail = True
                        break

                if fail:
                    continue

            source = SOURCE_APIS[source_data['api']](self, source_file, source_data)

            self.sources[source_data['prefix']] = source


    def load_ports(self):
        """
        Find all installed ports, because ports can be installed by zips we need to recheck every time.
        """
        port_files = list(self.ports_dir.glob('*/*.port.json'))
        port_files.sort()

        self.installed_ports = []
        self.unknown_ports = []
        self.broken_ports = []
        all_items = {}
        unknown_files = []

        ## Load all the known ports with port.json files
        for port_file in port_files:
            port_info = PortInfo(port_file)

            for item in port_info.items:
                add_unique_list(all_items, item, port_info.source)

            if port_info.items_opt is not None:
                for item in port_info.items_opt:
                    add_unique_list(all_items, item, port_info.source)

            bad = False
            for script_name in port_info.scripts:
                if not (self.ports_dir / script_name).is_file():
                    bad = True
                    break

            for dir_name in port_info.dirs:
                if not (self.ports_dir / dir_name).is_dir():
                    bad = True
                    break

            if bad:
                self.broken_ports.append(port_info)
            else:
                self.installed_ports.append(port_info)

        ## Check all files
        for file_item in self.ports_dir.iterdir():
            ## Skip these
            if file_item.name.lower() in (
                'portmaster', 'portmaster.sh',
                'thememaster', 'thememaster.sh',
                'harbourmaster',
                'images', 'videos', 'manuals',
                'gamelist.xml', 'gamelist.xml.old'):
                continue

            file_name = file_item.name
            if file_item.is_dir():
                file_name += '/'

            port_owners = get_list(all_items, file_name)

            if len(port_owners) == 0:
                if file_name.lower().endswith('.sh'):
                    unknown_files.append(file_name)

        ## Find any ports that match the files we couldnt find matchting a port.json file
        ports_info = None
        new_ports = []
        for unknown_file in unknown_files:
            if ports_info is None:
                from ports_info import ports_info

            port_owners = get_list(ports_info['items'], unknown_file)

            if len(port_owners) == 1:
                add_unique(new_ports, port_owners[0])
            elif len(port_owners) == 0:
                if unknown_file.endswith('.sh'):
                    ## Keep track of unknown bash scripts.
                    logger.info(f"Unknown port: {unknown_file}")
                    self.unknown_ports.append(unknown_file)

        ## Create new port.json files for any new ports, these only contain the most basic of information.
        for new_port in new_ports:
            if ports_info is None:
                from ports_info import ports_info

            port_info_raw = ports_info['ports'][new_port]

            port_info = PortInfo(port_info_raw)

            port_json = self.ports_dir / port_info_raw['file']
            if not port_json.parent.is_dir():
                ## CEBION WAS HERE!
                logger.info(f"Broken port: {port_info}")
                self.broken_ports.append(port_info)
                continue

            with port_json.open('w') as fh:
                json.dump(port_info.to_dict(), fh, indent=4)

            self.installed_ports.append(port_info)


    def port_info_attrs(self, port_info):
        runtime_fix = {
            'frt':  'godot',
            'mono': 'mono',
            'jdk11': 'jre',
            }

        attrs = []
        runtime = port_info.get('attr', {}).get('runtime', None)
        if runtime is not None:
            for runtime_key, runtime_attr in runtime_fix.items():
                if runtime_key in runtime:
                    add_unique(attrs, runtime_attr)

        for genre in port_info.get('attr', {}).get('genres', None):
            add_unique(attrs, genre.casefold())

        rtr = port_info.get('attr', {}).get('rtr', False)
        if rtr:
            add_unique(attrs, 'rtr')

        return attrs

    def match_filters(self, port_filters, port_info):
        port_attrs = self.port_info_attrs(port_info)

        for port_filter in port_filters:
            if port_filter.casefold() not in port_attrs:
                return False

        return True

    def list_ports(self, filters=[]):
        ## Filters can be genre, runtime

        ports = {}

        for source_prefix, source in self.sources.items():
            for port in source.ports:
                if port in ports:
                    continue

                port_info = source.port_info(port)

                if not self.match_filters(filters, port_info):
                    continue

                ports[port] = (source, port, port_info)

        return ports

    def install_port(self, download_info):
        """
        Installs a port.

        We collect a list of top level scripts/directories, this is added to the port.json file.
        """

        port_info_file = None
        items = []
        dirs = []
        scripts = []

        with zipfile.ZipFile(download_info.zip_file, 'r') as zf:
            for file_info in zf.infolist():
                if file_info.filename.startswith('/'):
                    ## Sneaky
                    logger.error(f"Port <b>{download_info.source}</b> has an illegal file {file_info.filename!r}, aborting.")
                    return 255

                if file_info.filename.startswith('../'):
                    ## Little
                    logger.error(f"Port <b>{download_info.source}</b> has an illegal file {file_info.filename!r}, aborting.")
                    return 255

                if '/../' in file_info.filename:
                    ## Shits
                    logger.error(f"Port <b>{download_info.source}</b> has an illegal file {file_info.filename!r}, aborting.")
                    return 255

                if '/' in file_info.filename:
                    parts = file_info.filename.split('/')

                    if parts[0] not in dirs:
                        items.append(parts[0] + '/')
                        dirs.append(parts[0])

                    if len(parts) == 2:
                        if parts[1].lower().endswith('.port.json'):
                            ## TODO: add the ability for multiple port folders to have multiple port.json files. ?
                            if port_info_file is not None:
                                logger.warning(f"Port <b>{download_info.source}</b> has multiple port.json files.")
                                logger.warning(f"- Before: <b>{port_info_file.relative_to(self.ports_dir)!r}</b>")
                                logger.warning(f"- Now:    <b>{file_info.filename!r}</b>")

                            port_info_file = self.ports_dir / file_info.filename

                    if file_info.filename.lower().endswith('.sh'):
                        logger.warning(f"Port <b>{download_info.source}</b> has <b>{file_info.filename}</b> inside, this can cause issues.")

                else:
                    if file_info.filename.lower().endswith('.sh'):
                        scripts.append(file_info.filename)
                        items.append(file_info.filename)
                    else:
                        logger.warning(f"Port <b>{download_info.source}</b> contains <b>{file_info.filename}</b> at the top level, but it is not a shell script.")

            if len(dirs) == 0:
                logger.error(f"Port <b>{download_info.source}</b> has no directories, aborting.")
                return 255

            if len(scripts) == 0:
                logger.error(f"Port <b>{download_info.source}</b> has no scripts, aborting.")
                return 255

            ## TODO: keep a list of installed files for uninstalling?
            # At this point the port will be installed
            # Extract all the files to the specified directory
            # zf.extractall(self.ports_dir)
            cprint("<b>Extracting port.</b>")
            for file_info in zf.infolist():
                if file_info.file_size == 0:
                    compress_saving = 100
                else:
                    compress_saving = file_info.compress_size / file_info.file_size * 100

                cprint(f"- <b>{file_info.filename!r}</b> <d>[{nice_size(file_info.file_size)} ({compress_saving:.0f}%)]</d>")
                zf.extract(file_info, path=self.ports_dir)

        if port_info_file is not None:
            port_info = PortInfo(port_info_file)
        else:
            port_info = PortInfo({})

        # print(f"Port Info: {port_info}")
        # print(f"Download Info: {download_info}")

        port_info.merge_info(download_info)

        ## These two are always overriden.
        port_info.items = items
        port_info.md5 = download_info.md5

        if port_info_file is None:
            port_info_file = self.ports_dir / dirs[0] / (download_info.zip_file.stem + '.port.json')

        # print(f"Merged Info: {port_info}")

        with open(port_info_file, 'w') as fh:
            json.dump(port_info.to_dict(), fh, indent=4)

        return self.check_runtime(port_info)

    def check_runtime(self, port_info):
        runtime = port_info.attr.get('runtime', None)
        if isinstance(runtime, str):
            if '/' in runtime:
                logger.error(f"Bad runtime <b>{runtime}</b>")
                return 255

            runtime_file = (self.libs_dir / runtime)
            if not runtime_file.is_file():
                for source_prefix, source in self.sources.items():
                    if runtime in source.utils:
                        cprint(f"Downloading required runtime <b>{runtime}</b>.")

                        try:
                            runtime_download = source.download(runtime, temp_dir=self.libs_dir)

                        except Exception as err:
                            ## We need to catch any errors and delete the file if it fails,
                            ## here we are not using the temp file auto deletion.
                            if runtime_file.is_file():
                                runtime_file.unlink()

                            raise err

                        return 0
                else:
                    logger.error(f"Unable to find suitable source for {runtime}.")
                    return 0
                    # return 255


################################################################################
## Self updater url
HM_UPDATE_URLS = {
    "harbourmaster": "https://github.com/kloptops/harbourmaster/raw/main/harbourmaster.md5",
    "pylibs.zip": "https://github.com/kloptops/harbourmaster/raw/main/pylibs.zip.md5",
    }

def self_upgrade():
    """
    Self-upgrading code.
    """
    if TESTING:
        cprint("<error>Unable to update in test environment.</error>")
        return 255

    self_path = Path(__file__).parent

    if not self_path.is_absolute():
        self_path = self_path.absolute()

    results = []

    cprint("<b>Performing Self Upgrade.</b>")
    for file_name, file_url_md5 in HM_UPDATE_URLS.items():
        if not file_url_md5.endswith('.md5'):
            logger.error("Self Upgrade: Something is funky, quitting.")
            return 255

        file_url = file_url_md5.rsplit('.', 1)[0]

        file_md5_result = fetch_text(file_url_md5)
        if file_md5_result is None:
            logger.error(f"Self Upgrade: File download failed. [<b>{file_url_md5}</b>]")
            return 255

        file_md5_result = file_md5_result.strip()

        if file_name == 'pylibs.zip':
            if (self_path / (file_name + '.md5')).is_file():
                if (self_path / (file_name + '.md5')).read_text().strip() == file_md5_result:
                    cprint(f"- skipping <b>{file_name!r}</b>, already up to date. [<b>{file_md5_result}</b>]")
                    continue

        elif (self_path / file_name).is_file():
            md5 = hashlib.md5()
            with open(self_path / file_name, 'rb') as fh:
                md5.update(fh.read())

            if md5.hexdigest() == file_md5_result:
                cprint(f"- skipping <b>{file_name!r}</b>, already up to date. [<b>{file_md5_result}</b>]")
                continue

        file_data = fetch_data(file_url)
        if file_data is None:
            logger.error(f"Self Upgrade: File download failed. [<b>{file_url}</b>]")
            return 255

        md5 = hashlib.md5()
        md5.update(file_data)
        file_md5_check = md5.hexdigest()

        if file_md5_check != file_md5_result:
            logger.error(f"Self Upgrade: MD5 sum doesn't match. [<b>{file_md5_check}</b> vs <b>{file_md5_result}</b>]")
            return 255

        results.append((file_name, file_data))

    if len(results) == 0:
        cprint("<b>Skipping, harbourmaster is already up to date.</b>")

    else:
        cprint("<b,g,>Succesfully fetched files, updating.</b,g,>")
        for file_name, file_data in results:
            cprint(f"- updating <b>{file_name!r}</b>")
            with open(self_path / file_name, 'wb') as fh:
                fh.write(file_data)
            cprint( "  done.")

        cprint("<b>All Done!</b>")

    return 0


################################################################################
## Commands

def do_update(hm, argv):
    """
    Update available ports, checks for new releases.
    """
    if len(argv) == 0:
        argv = ('all', )

    if argv[0].lower() == 'all':
        cprint('<b>Updating all port sources:</b>')
        for source in hm.sources:
            hm.sources[source].update()
    else:
        for arg in argv:
            if arg not in hm.sources:
                cprint(f'<warn>Unknown source {arg}</warn>')
                continue

            cprint(f'<b>Updating {arg}:<b/>')
            hm.sources[arg].update()

    return 0


def do_list(hm, argv):
    """
    List available ports

    {command} list [filters]
    """
    ports = hm.list_ports(argv)
    available_filters = set()

    cprint("Available ports:")
    for port in sorted(ports.keys(), key=lambda port: ports[port][2]['attr']['title'].casefold()):
        port_info = ports[port][2]

        cprint(f"- <d>{ports[port][0]._prefix}</d>/<b>{port}<b>: <b,g,>{port_info['attr']['title']}</b,g,>")
        cprint("")
        cprint('\n'.join(textwrap.wrap(port_info['attr']['desc'], width=70, initial_indent='    ', subsequent_indent='    ')))
        cprint("")
        cprint("")

        available_filters.update(hm.port_info_attrs(ports[port][2]))

    available_filters -= set(argv)

    cprint(f'<r>Filters</r>: <m>{", ".join(sorted(available_filters))}</m>')

    return 0


def do_ports(hm, argv):
    """
    List installed ports

    {command} ports [filters]
    """
    if len(hm.installed_ports) > 0:
        cprint("<b,g,>Installed Ports:</b,g,>")
        for port_info in hm.installed_ports:
            cprint(f"- <b>{port_info.source}</b>")

        cprint()

    if len(hm.unknown_ports) > 0:
        cprint("<warn>Unknown Ports:</warn>")
        for file_name in hm.unknown_ports:
            cprint(f"- <b>{file_name}</b>")

        cprint()

    if len(hm.broken_ports) > 0:
        cprint("<error>Broken Ports:</error>")
        for port_info in hm.broken_ports:
            cprint(f"- <b>{port_info.source}</b>")

        cprint()

    if sum((len(hm.installed_ports), len(hm.unknown_ports), len(hm.broken_ports))) == 0:
        cprint("No ports found.")

        cprint()

    return 0


def do_portsmd(hm, argv):
    """
    List available ports in a format portmaster can use.

    {command} portsmd
    """
    if len(argv) > 0:
        results = []
        for arg in argv:
            if arg == '':
                continue

            if ',' in arg:
                results.extend([
                    x
                    for x in arg.split(',')
                    if x != ''])
            else:
                results.append(arg)

        argv = results

    ports = hm.list_ports(argv)
    available_filters = set()

    cprint()
    for port in sorted(ports.keys(), key=lambda port: ports[port][2]['attr']['title'].casefold()):
        cprint(ports[port][0].portmd(port))
        cprint()
        available_filters.update(hm.port_info_attrs(ports[port][2]))

    available_filters -= set(argv)

    cprint(f'<r>Filters</r>="<m>{",".join(sorted(available_filters))}</m>"')

    return 0


def do_install(hm, argv):
    """
    Install a port

    {command} install Half-Life.zip               # Install from highest priority repo
    {command} install */Half-Life.zip             # Same as above.
    {command} install pm/Half-Life.zip            # Install specifically from Portmaster repo
    {command} install klops/Half-Life.zip         # Install specifically from Kloptops repo
    {command} install https://example.com/example_port.zip # Download a port from a url
    """
    if len(argv) == 0:
        cprint("Missing arguments.")
        return do_help(hm, ['install'])

    for arg in argv:
        if arg.startswith('http'):
            download_info = raw_download(hm.temp_dir, arg)

            if download_info is None:
                return 255

            result = hm.install_port(download_info)
            if result != 0:
                return result

            continue

        if '/' in arg:
            repo, port_name = arg.split('/', 1)
        else:
            repo = '*'
            port_name = arg

        for source_prefix, source in hm.sources.items():
            if not fnmatch.fnmatch(source_prefix, repo):
                continue

            if source.clean_name(port_name) not in source.ports:
                continue

            download_info = source.download(source.clean_name(port_name))

            if download_info is None:
                return 255

            # print(f"Download Info: {download_info.to_dict()}")
            result = hm.install_port(download_info)
            if result != 0:
                return result

            break
        else:
            cprint(f"Unable to find a source for <b>{port_name}</b>")

    return 0


def do_upgrade(hm, argv):
    """
    Upgrade a port

    {command} upgrade Half-Life.zip               # Update from highest priority repo
    {command} upgrade */Half-Life.zip             # Same as above.
    {command} upgrade pm/Half-Life.zip            # Update specifically from portmaster repo
    """

    if len(argv) == 0:
        cprint("Missing arguments.")
        return do_help(hm, ['upgrade'])

    if len(argv) == 1 and argv[0] == 'harbourmaster':
        ## SPECIAL CASE!

        return self_upgrade()

    logger.error("Error: Not yet implemented.")
    return 255


def do_fifo_control(hm, argv):
    """
    {command} fifo_control /dev/shm/portmaster/hm_input > /dev/null &

    echo "portsmd:/dev/shm/portmaster/ports.md:" > /dev/shm/portmaster/hm_input

    """
    if len(argv) == 0:
        return 0

    with open(argv[0], 'r') as pipe:
        while True:
            args = pipe.readline().strip()
            if not args:
                continue

            args = args.split(':')

            if args[0] == 'exit':
                return 0

            orig_stdout = sys.stdout

            with open(args[1], 'w') as fh:
                sys.stdout = fh
                all_commands[args[0].casefold()](hm, args[2:])

            sys.stdout = orig_stdout


def do_help(hm, argv):
    """
    Shows general help or help for a particular command.

    {command} help
    {command} help list
    """
    command = sys.argv[0]
    if '/' in command:
        command = command.rsplit('/', 1)[1]

    if len(argv) > 0:
        if argv[0].lower() not in all_commands:
            cprint(f"Error: unknown help command <b>{argv[0]}</b>")
            do_help(hm, build_configs, [])
            return

        cprint(textwrap.dedent(all_commands[argv[0].lower()].__doc__.format(command=command)).strip())
        return

    cprint(f"{command} <d>[flags]</d> <b><update></b> <d>[source or all]</d> ")
    cprint(f"{command} <d>[flags]</d> <b><install/upgrade></b> <d>[source/]</d><port_name>.zip ")
    # print(f"{command} <d>[flags]</d> <uninstall> [source/]<port_name> ")
    cprint(f"{command} <d>[flags]</d> <b><list/portsmd></b> <d>[source or all]</d> <d>[... filters]</d>")
    cprint(f"{command} <d>[flags]</d> <b><ports></b>")
    cprint(f"{command} <d>[flags]</d> <b><help></b> <command>")
    cprint()
    cprint("Flags:")
    cprint("  --quiet        - less text")
    cprint("  --debug        - more text")
    cprint("  --no-check     - dont check for ports updates unless you run <b>update</b>")
    cprint("  --force-colour - force colour output")
    cprint("  --no-colour    - force no colour output")
    cprint("  --no-log       - do not log to harbourmaster.txt")
    cprint()
    cprint("All available commands: <b>" + ('</b>, <b>'.join(all_commands.keys())) + "</b>")
    cprint()


all_commands = {
    'update': do_update,
    'portsmd': do_portsmd,
    'ports': do_ports,
    'list': do_list,
    'install': do_install,
    'upgrade': do_upgrade,
    'help': do_help,
    }

@logger.catch
def main(argv):
    global LOG_FILE_HANDLE

    with make_temp_directory() as temp_dir:
        argv = argv[:]

        config = {
            'quiet': False,
            'no-check': False,
            'debug': False,
            'no-colour': False,
            'force-colour': False,
            'no-log': False,
            'help': False,
            }

        i = 1
        while i < len(argv):
            if argv[i] == '--':
                del argv[i]
                break

            if argv[i].startswith('--'):
                if argv[i][2:] in config:
                    config[argv[i][2:]] = True
                else:
                    if not config['quiet']:
                        logger.error(f"unknown argument <b>{argv}</b>")

                del argv[i]
                continue

            i += 1

        if config['quiet']:
            logger.configure(handlers=[{"sink": sys.stderr, "level": "ERROR"}])
        elif config['debug']:
            logger.configure(handlers=[{"sink": sys.stderr, "level": "DEBUG"}])

        if config['no-log']:
            logger.remove(LOG_FILE_HANDLE)
            LOG_FILE_HANDLE = None

        if config['no-colour']:
            utility.do_color(False)
        elif config['force-colour']:
            utility.do_color(True)

        hm = HarbourMaster(config, temp_dir=temp_dir)

        if config['help']:
            all_commands['help'](hm, argv[1:])
            return 1

        if len(argv) == 1:
            all_commands['help'](hm, [])
            return 1

        if argv[1].casefold() == 'nothing':
            ## This is used to lazily update sources.
            return 0

        if argv[1].casefold() == 'fifo_control':
            do_fifo_control(hm, argv[2:])
            return 0

        if argv[1].casefold() not in all_commands:
            cprint(f'Command <b>{argv[1]}</b> not found.')
            all_commands['help'](hm, [])
            return 2

        return all_commands[argv[1].casefold()](hm, argv[2:])


if __name__ == '__main__':
    exit(main(sys.argv))
